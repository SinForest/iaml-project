=> loading dataset <=
removed 98574/106574 non-existing/too short items
=> dataset loaded <=
Model(
  (conv): Sequential(
    (0): Conv1d(1, 16, kernel_size=(3,), stride=(3,), padding=(1,))
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (7): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (11): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (15): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    (16): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU()
    (18): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (19): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): ReLU()
    (22): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (23): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (24): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (25): ReLU()
    (26): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (27): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))
    (28): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU()
    (30): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (31): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
    (32): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (33): ReLU()
    (34): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (35): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))
    (36): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (37): ReLU()
    (38): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (39): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (40): Dropout(p=0.5)
  )
  (fc): Sequential(
    (0): Linear(in_features=512, out_features=8, bias=True)
    (1): Sigmoid()
  )
)
=> begin training <=
training epoch 0
train precision: 26.70%
validation precision: 34.19%
training epoch 1
train precision: 32.00%
validation precision: 31.94%
training epoch 2
train precision: 33.86%
validation precision: 34.56%
training epoch 3
train precision: 35.06%
validation precision: 38.12%
training epoch 4
train precision: 36.36%
validation precision: 38.19%
training epoch 5
train precision: 36.23%
validation precision: 36.44%
Epoch     5: reducing learning rate of group 0 to 5.0000e-03.
training epoch 6
train precision: 38.16%
validation precision: 41.62%
training epoch 7
train precision: 39.12%
validation precision: 40.94%
Epoch     7: reducing learning rate of group 0 to 2.5000e-03.
training epoch 8
train precision: 40.66%
validation precision: 42.38%
training epoch 9
train precision: 40.94%
validation precision: 41.00%
Epoch     9: reducing learning rate of group 0 to 1.2500e-03.
training epoch 10
train precision: 41.61%
validation precision: 44.00%
training epoch 11
train precision: 42.11%
validation precision: 43.50%
Epoch    11: reducing learning rate of group 0 to 6.2500e-04.
training epoch 12
train precision: 42.42%
validation precision: 44.69%
training epoch 13
train precision: 43.62%
validation precision: 43.88%
Epoch    13: reducing learning rate of group 0 to 3.1250e-04.
training epoch 14
train precision: 43.48%
validation precision: 43.62%
training epoch 15
train precision: 43.53%
validation precision: 45.38%
Epoch    15: reducing learning rate of group 0 to 1.5625e-04.
training epoch 16
train precision: 43.56%
validation precision: 45.62%
training epoch 17
train precision: 43.91%
validation precision: 44.81%
Epoch    17: reducing learning rate of group 0 to 7.8125e-05.
training epoch 18
train precision: 43.61%
validation precision: 44.69%
training epoch 19
train precision: 43.11%
validation precision: 45.75%
training epoch 20
train precision: 42.47%
validation precision: 44.56%
Epoch    20: reducing learning rate of group 0 to 3.9063e-05.
training epoch 21
train precision: 43.66%
validation precision: 45.56%
training epoch 22
train precision: 43.02%
validation precision: 44.81%
Epoch    22: reducing learning rate of group 0 to 1.9531e-05.
training epoch 23
train precision: 43.33%
validation precision: 44.75%
training epoch 24
train precision: 43.34%
validation precision: 45.81%
Epoch    24: reducing learning rate of group 0 to 9.7656e-06.
training epoch 25
train precision: 43.89%
validation precision: 46.00%
training epoch 26
train precision: 43.47%
validation precision: 44.81%
Epoch    26: reducing learning rate of group 0 to 4.8828e-06.
training epoch 27
train precision: 43.92%
validation precision: 43.25%
training epoch 28
train precision: 43.05%
validation precision: 44.81%
Epoch    28: reducing learning rate of group 0 to 2.4414e-06.
training epoch 29
train precision: 44.28%
validation precision: 45.25%
training epoch 30
train precision: 43.75%
validation precision: 45.88%
Epoch    30: reducing learning rate of group 0 to 1.2207e-06.
training epoch 31
train precision: 43.52%
validation precision: 44.69%
training epoch 32
train precision: 43.66%
validation precision: 46.00%
training epoch 33
train precision: 42.81%
validation precision: 46.19%
Epoch    33: reducing learning rate of group 0 to 6.1035e-07.
training epoch 34
train precision: 43.19%
validation precision: 45.88%
training epoch 35
train precision: 43.09%
validation precision: 44.88%
Epoch    35: reducing learning rate of group 0 to 3.0518e-07.
training epoch 36
train precision: 42.91%
validation precision: 44.94%
training epoch 37
train precision: 44.05%
validation precision: 44.81%
Epoch    37: reducing learning rate of group 0 to 1.5259e-07.
training epoch 38
train precision: 43.02%
validation precision: 44.75%
training epoch 39
train precision: 43.81%
validation precision: 44.88%
Epoch    39: reducing learning rate of group 0 to 7.6294e-08.
training epoch 40
train precision: 43.31%
validation precision: 44.56%
training epoch 41
train precision: 43.73%
validation precision: 44.00%
Epoch    41: reducing learning rate of group 0 to 3.8147e-08.
training epoch 42
train precision: 43.83%
validation precision: 46.19%
training epoch 43
train precision: 43.56%
validation precision: 44.38%
Epoch    43: reducing learning rate of group 0 to 1.9073e-08.
training epoch 44
train precision: 42.92%
validation precision: 45.38%
training epoch 45
train precision: 43.39%
validation precision: 44.75%
training epoch 46
train precision: 44.25%
validation precision: 44.94%
training epoch 47
train precision: 43.53%
validation precision: 43.12%
training epoch 48
train precision: 42.91%
validation precision: 44.69%
training epoch 49
train precision: 44.75%
validation precision: 45.69%
training epoch 50
train precision: 44.12%
validation precision: 44.56%
training epoch 51
train precision: 43.44%
validation precision: 44.44%
training epoch 52
