Model(
  (conv): Sequential(
    (0): Conv1d(1, 16, kernel_size=(3,), stride=(3,), padding=(1,))
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (7): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (11): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (15): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    (16): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU()
    (18): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (19): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): ReLU()
    (22): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (23): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    (24): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (25): ReLU()
    (26): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (27): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))
    (28): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU()
    (30): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (31): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
    (32): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (33): ReLU()
    (34): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (35): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))
    (36): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (37): ReLU()
    (38): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (39): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
    (40): Dropout(p=0.5)
  )
  (fc): Sequential(
    (0): Linear(in_features=512, out_features=8, bias=True)
    (1): Sigmoid()
  )
)


=> begin training <=
training epoch 0: 100%|███████████████████████| 400/400 [30:19<00:00,  4.55s/it]
train precision: 27.09%
validation epoch 0: 100%|█████████████████████| 100/100 [07:40<00:00,  3.20s/it]
validation precision: 29.75%
validation running loss: 190.5211%
training epoch 1: 100%|███████████████████████| 400/400 [30:31<00:00,  4.58s/it]
train precision: 32.80%
validation epoch 1: 100%|█████████████████████| 100/100 [07:34<00:00,  4.55s/it]
validation precision: 35.75%
validation running loss: 183.9336%
training epoch 2: 100%|███████████████████████| 400/400 [30:51<00:00,  4.63s/it]
train precision: 36.19%
validation epoch 2: 100%|█████████████████████| 100/100 [07:42<00:00,  4.63s/it]
validation precision: 33.50%
validation running loss: 187.2691%
Epoch     2: reducing learning rate of group 0 to 5.0000e-03.
training epoch 3: 100%|███████████████████████| 400/400 [30:43<00:00,  4.61s/it]
train precision: 38.06%
validation epoch 3: 100%|█████████████████████| 100/100 [07:41<00:00,  4.62s/it]
validation precision: 40.31%
validation running loss: 179.8222%
training epoch 4: 100%|███████████████████████| 400/400 [31:20<00:00,  3.82s/it]
train precision: 40.22%
validation epoch 4: 100%|█████████████████████| 100/100 [07:51<00:00,  4.72s/it]
validation precision: 41.56%
validation running loss: 178.0699%
training epoch 5: 100%|███████████████████████| 400/400 [31:54<00:00,  4.79s/it]
train precision: 40.73%
validation epoch 5: 100%|█████████████████████| 100/100 [08:02<00:00,  2.68s/it]
validation precision: 41.56%
validation running loss: 179.3178%
Epoch     5: reducing learning rate of group 0 to 2.5000e-03.
training epoch 6: 100%|███████████████████████| 400/400 [32:20<00:00,  4.85s/it]
train precision: 44.61%
validation epoch 6: 100%|█████████████████████| 100/100 [07:58<00:00,  2.74s/it]
validation precision: 43.94%
validation running loss: 177.4017%
training epoch 7: 100%|███████████████████████| 400/400 [31:58<00:00,  4.80s/it]
train precision: 45.94%
validation epoch 7: 100%|█████████████████████| 100/100 [07:59<00:00,  4.79s/it]
validation precision: 45.38%
validation running loss: 176.8881%
training epoch 8: 100%|███████████████████████| 400/400 [32:14<00:00,  4.84s/it]
train precision: 47.75%
validation epoch 8: 100%|█████████████████████| 100/100 [07:48<00:00,  4.69s/it]
validation precision: 43.62%
validation running loss: 177.1853%
Epoch     8: reducing learning rate of group 0 to 1.2500e-03.
training epoch 9: 100%|███████████████████████| 400/400 [33:01<00:00,  4.95s/it]
train precision: 50.70%
validation epoch 9: 100%|█████████████████████| 100/100 [08:31<00:00,  5.11s/it]
validation precision: 43.94%
validation running loss: 176.4527%
training epoch 10: 100%|██████████████████████| 400/400 [33:17<00:00,  4.99s/it]
train precision: 52.16%
validation epoch 10: 100%|████████████████████| 100/100 [08:15<00:00,  4.95s/it]
validation precision: 44.12%
validation running loss: 176.5642%
Epoch    10: reducing learning rate of group 0 to 6.2500e-04.
training epoch 11: 100%|██████████████████████| 400/400 [32:37<00:00,  5.17s/it]
train precision: 53.64%
validation epoch 11: 100%|████████████████████| 100/100 [08:14<00:00,  2.01s/it]
validation precision: 44.44%
validation running loss: 175.9165%
